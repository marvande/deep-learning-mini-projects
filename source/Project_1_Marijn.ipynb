{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Classification, weight sharing, auxiliary losses \n",
    "\n",
    "\n",
    "The objective of this project is to test different architectures to compare two digits visible in a\n",
    "two-channel image. It aims at showing in particular the impact of weight sharing, and of the use of an\n",
    "auxiliary loss to help the training of the main objective.\n",
    "It should be implemented with PyTorch only code, in particular without using other external libraries\n",
    "such as scikit-learn or numpy.\n",
    "\n",
    "The goal of this project is to implement a deep network such that, given as input a series of 2 ×14×14\n",
    "tensor, corresponding to pairs of 14 × 14 grayscale images, it predicts for each pair if the first digit is\n",
    "lesser or equal to the second. The training and test set should be 1, 000 pairs each, and the size of the images allows to run experiments rapidly, even in the VM with a single core and no GPU.\n",
    "You can generate the data sets to use with the function generate˙pair˙sets(N) defined in the file\n",
    "dlc˙practical˙prologue.py. This function returns six tensors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import argparse\n",
    "import os\n",
    "import urllib\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from sklearn.metrics import roc_auc_score # roc auc metric\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from dlc_practical_prologue import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signSGD import signSGD\n",
    "from Nadam import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control the randomness\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/'):\n",
    "    os.makedirs('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\\n!tar -zxvf MNIST.tar.gz\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this once to download the MNIST data-set. \n",
    "# There is a problem with the server on which it's hosted so only way right now \n",
    "# to have it :( \n",
    "\n",
    "\"\"\"\n",
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(\n",
    "    1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training and test input size: {train_input.size(), test_input.size()}')\n",
    "print(f'Training and test target size: {train_target.size(), test_target.size()}')\n",
    "print(f'Training and test classes size: {train_classes.size(), test_classes.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dataset needed for training. For this as we have a special data case we rewrite the `Dataset` class in order to use a `dataloader` later. Remember `target` is 1 if first number is smaller or equal than the second image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, pairs, target, classes):\n",
    "        'Initialization'\n",
    "        # target = (0,1)\n",
    "        self.target = target\n",
    "        # image pairs (2,14,14)\n",
    "        self.pairs = pairs\n",
    "        # cipher classes (2 in [0,9])\n",
    "        self.classes = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # image pairs\n",
    "        X = self.pairs[index]\n",
    "        # target:\n",
    "        y = self.target[index]\n",
    "        # classes:\n",
    "        Y = self.classes[index]\n",
    "        return X, y, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datasets (training and validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(train_input, train_target, train_classes)\n",
    "test_set = Dataset(test_input, test_target, test_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6, 2, figsize=(5, 18))\n",
    "for j in range(6):\n",
    "    im1 = training_set.__getitem__(j)[0][0, :, :]\n",
    "    im2 = training_set.__getitem__(j)[0][1, :, :]\n",
    "    target = training_set.__getitem__(j)[1]\n",
    "    classes = training_set.__getitem__(j)[2]\n",
    "    ax[j, 0].imshow(im1, cmap='gray')\n",
    "    ax[j, 1].imshow(im2, cmap='gray')\n",
    "    ax[j, 1].set_title(f'Cipher: {classes[1]}')\n",
    "    ax[j, 0].set_title(f'Cipher: {classes[0]}, target: {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architectures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline: \n",
    "- Loss: CE (cross entropy) \n",
    "- Optimizer: SGD optimizer\n",
    "- Activation function: softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model with two layers and a two digit output:\n",
    "class Model_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        input_size = 2 * 14 * 14\n",
    "        hidden_sizes = [392, 392]\n",
    "        # two digit output, probability of being 1 or 0:\n",
    "        output_size = 2\n",
    "        # flatten images to 1D input:\n",
    "        self.flatten = nn.Flatten()\n",
    "        # then two hidden layers:\n",
    "        self.model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_sizes[1], output_size))\n",
    "        # no need to add softmax at the end because already in CE loss.\n",
    "    def forward(self, x):\n",
    "        # flatten 2D->1D\n",
    "        x = self.flatten(x)\n",
    "        # predict probabilities:\n",
    "        logits = self.model(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Siamese-RNN: \n",
    "- Two RNN - flatten outputs of both, concatenate and then linear model over it. \n",
    "- Loss: CE (cross entropy) \n",
    "- Optimizer: Adam optimizer\n",
    "- Activation function: softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRNN(nn.Module):\n",
    "\n",
    "    # declaraction of variables\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(ImageRNN, self).__init__()\n",
    "\n",
    "        # we need an intermediate output, because we are using a siamese RNN network\n",
    "        intermediate_output_size = 10\n",
    "\n",
    "        # two digit output, probability of being 1 or 0:\n",
    "        output_size = 2\n",
    "\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        # flatten images to 1D input:\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons,  bias=False)\n",
    "\n",
    "        self.FC = nn.Linear(self.n_neurons, intermediate_output_size, bias=False)\n",
    "        self.fcout = nn.Linear(2*intermediate_output_size, output_size,  bias=False)\n",
    "        \n",
    "        \n",
    "    # initialize hidden weights that have zero values\n",
    "    def init_hidden(self, ):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X1 = X[:, 0, :].view(-1, 14, 14).permute(1, 0, 2)\n",
    "        X2 = X[:, 1, :].view(-1, 14, 14).permute(1, 0, 2)\n",
    "        # X1.shape = torch.Size([14, 64, 14])\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # Input image 1 (first image of the pair)\n",
    "        # Predict the number on first image\n",
    "        # ------------------------------------------------------------------\n",
    "        self.batch_size = X1.size(1)\n",
    "        self.hidden = self.init_hidden() \n",
    "        #self.hidden.shape = torch.Size([1, 40, 50])\n",
    "        \n",
    "        # lstm_out => n_steps, batch_size, n_neurons (hidden states for each time step)\n",
    "        # self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\n",
    "        lstm_out, self.hidden = self.basic_rnn(X1, self.hidden)\n",
    "\n",
    "        # lstm_out.shape = torch.Size([14, 64, 50]) \n",
    "        # self.hidden.shape = torch.Size([1, 64, 50])\n",
    "        \n",
    "        # Size batch x 10 (cipher predictions on image)\n",
    "        out1 = self.FC(self.hidden)\n",
    "        # out1.shape = torch.Size([1, 64, 10])\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # Input image 2 (second image of the pair)\n",
    "        # Predict the number on second image\n",
    "        # ------------------------------------------------------------------\n",
    "        self.batch_size = X2.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # lstm_out => n_steps, batch_size, n_neurons (hidden states for each time step)\n",
    "        # self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\n",
    "        lstm_out, self.hidden = self.basic_rnn(X2, self.hidden)\n",
    "        \n",
    "        # Size batch x 10 (cipher predictions on image)\n",
    "        out2 = self.FC(self.hidden)\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # 0-1 Prediction \n",
    "        # Predict if first image bigger than second\n",
    "        # ------------------------------------------------------------------\n",
    "        \n",
    "        # concatenate into size (batch x 20)\n",
    "        output = torch.cat((out1[0], out2[0]), 1)   \n",
    "        # output.shape = torch.Size([64, 20])\n",
    "        \n",
    "        # flatten 2D->1D\n",
    "        output_ = self.flatten(output)     \n",
    "        # output_.shape = torch.Size([64, 20])        \n",
    "        \n",
    "        # predict probabilities:\n",
    "        logits = self.fcout(output_)\n",
    "        return out1.view(-1, self.n_outputs), out2.view(\n",
    "            -1, self.n_outputs), logits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Siamese RNN 2 (longer linear part): \n",
    "- Two RNN - flatten outputs of both, concatenate and then linear model over it\n",
    "- Longer linear model here\n",
    "- Loss: CE (cross entropy)\n",
    "- Optimizer: Adam optimizer\n",
    "- Activation function: softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRNN_2(nn.Module):\n",
    "\n",
    "    # declaraction of variables\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(ImageRNN_2, self).__init__()\n",
    "\n",
    "        # we need an intermediate output, because we are using a siamese RNN network\n",
    "        intermediate_output_size = 10\n",
    "\n",
    "        # two digit output, probability of being 1 or 0:\n",
    "        fina_output_size = 2\n",
    "\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        # flatten images to 1D input:\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons,  bias=False)\n",
    "\n",
    "        self.FC = nn.Linear(self.n_neurons, intermediate_output_size, bias=False)\n",
    "        self.fcout = nn.Linear(2*intermediate_output_size, fina_output_size,  bias=False)\n",
    "        \n",
    "        # Input last linear model:\n",
    "        input_size = 2 * 10\n",
    "        hidden_sizes = [150, 150]\n",
    "        \n",
    "        # then two hidden layers:\n",
    "        self.final = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_sizes[1], fina_output_size))\n",
    "        \n",
    "        \n",
    "    # initialize hidden weights that have zero values\n",
    "    def init_hidden(self, ):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X1 = X[:, 0, :].view(-1, 14, 14).permute(1, 0, 2)\n",
    "        X2 = X[:, 1, :].view(-1, 14, 14).permute(1, 0, 2)\n",
    "        # X1.shape = torch.Size([14, 64, 14])\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Input image 1 (first image of the pair)\n",
    "        # Predict the number on first image\n",
    "        # ------------------------------------------------------------------\n",
    "        self.batch_size = X1.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # lstm_out => n_steps, batch_size, n_neurons (hidden states for each time step)\n",
    "        # self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\n",
    "        lstm_out, self.hidden = self.basic_rnn(X1, self.hidden)\n",
    "        # lstm_out.shape = torch.Size([14, 64, 50]) \n",
    "        # self.hidden.shape = torch.Size([1, 64, 50])\n",
    "\n",
    "        # Size batch x 10 (cipher predictions on image)\n",
    "        out1 = self.FC(self.hidden)\n",
    "        # out1.shape = torch.Size([1, 64, 10])\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Input image 2 (second image of the pair)\n",
    "        # Predict the number on second image\n",
    "        # ------------------------------------------------------------------\n",
    "        self.batch_size = X2.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # lstm_out => n_steps, batch_size, n_neurons (hidden states for each time step)\n",
    "        # self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\n",
    "        lstm_out, self.hidden = self.basic_rnn(X2, self.hidden)\n",
    "        \n",
    "        # Size batch x 10 (cipher predictions on image)\n",
    "        out2 = self.FC(self.hidden)\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # 0-1 Prediction \n",
    "        # Predict if first image bigger than second\n",
    "        # ------------------------------------------------------------------\n",
    "        \n",
    "        # concatenate into size (batch x 20)\n",
    "        output = torch.cat((out1[0], out2[0]), 1)   \n",
    "        # output.shape = torch.Size([64, 20])\n",
    "\n",
    "        # flatten 2D->1D\n",
    "        output_ = self.flatten(output)      \n",
    "        \n",
    "        # predict probabilities:\n",
    "        #logits = self.fcout(output_)\n",
    "        logits = self.final(output_)\n",
    "        return out1.view(-1, self.n_outputs), out2.view(\n",
    "            -1, self.n_outputs), logits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Siamese CNN:\n",
    "\n",
    "Basic CNN with two layers and two linear layers. \n",
    "- Siamese CNN\n",
    "- Auxiliary losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Conv_basic(nn.Module):\n",
    "    # declaraction of variables\n",
    "    def __init__(self):\n",
    "        super(Conv_basic, self).__init__()\n",
    "\n",
    "        # we need an intermediate output, because we are using a siamese RNN network\n",
    "        intermediate_output_size = 10\n",
    "\n",
    "        # two digit output, probability of being 1 or 0:\n",
    "        fina_output_size = 2\n",
    "        self.n_outputs = 10\n",
    "        # flatten images to 1D input:\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(40, 30)\n",
    "        self.fc2 = nn.Linear(30, 10)\n",
    "        \n",
    "        self.fcout = nn.Linear(2 * intermediate_output_size,\n",
    "                               fina_output_size,\n",
    "                               bias=False)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X1 = X[:, 0, :].view(-1, 1, 14, 14)\n",
    "        X2 = X[:, 1, :].view(-1, 1, 14, 14)\n",
    "        # X1.shape = torch.Size([64, 1, 14, 14])\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # Input image 1 (first image of the pair)\n",
    "        # Predict the number on first image\n",
    "        # ------------------------------------------------------------------\n",
    "        x = F.relu(F.max_pool2d(self.conv1(X1), 2))\n",
    "        # x.shape = torch.Size([64, 10, 5, 5])\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        # x.shape = torch.Size([64, 10, 2, 2])\n",
    "        x = x.view(-1, 40)\n",
    "        # x.shape = torch.Size([64, 40])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x.shape = torch.Size([64, 30])\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # x.shape = torch.Size([64, 30])\n",
    "        \n",
    "        # Size batch x 10 (cipher predictions on image)\n",
    "        out1 = self.fc2(x)\n",
    "        # out1.shape = torch.Size([64, 10])\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # Input image 2 (second image of the pair)\n",
    "        # Predict the number on second image\n",
    "        # ------------------------------------------------------------------\n",
    "        x = F.relu(F.max_pool2d(self.conv1(X2), 2))\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = x.view(-1, 40)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # Size batch x 10 (cipher predictions on image)\n",
    "        out2 = self.fc2(x)\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # 0-1 Prediction\n",
    "        # Predict if first image bigger than second\n",
    "        # ------------------------------------------------------------------\n",
    "\n",
    "        # concatenate into size (batch x 20)\n",
    "        #X = self.flatten(X)\n",
    "        output = torch.cat((out1, out2), 1)\n",
    "        # flatten 2D->1D\n",
    "        output_ = self.flatten(output)\n",
    "        \n",
    "        # predict probabilities:\n",
    "        logits = self.fcout(output_)\n",
    "        return out1.view(-1, self.n_outputs), out2.view(-1,\n",
    "                                                        self.n_outputs), logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Siamese CNN (best model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model with two layers and a two digit output:\n",
    "class SiameseConvNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseConvNet2, self).__init__()\n",
    "        self.length = 14\n",
    "        self.input_size = 1 * 14 * 14\n",
    "        # we need an intermediate output, because we are using a siamese network\n",
    "        intermediate_output_size = 10\n",
    "        self.n_outputs = 10\n",
    "        # two digit output, probability of being 1 or 0:\n",
    "        final_output_size = 2\n",
    "        \n",
    "        # flatten images to 1D input:\n",
    "        self.flatten = nn.Flatten()\n",
    "        # convolutional layers\n",
    "        kernel_size = 3\n",
    "        n_channel = 5\n",
    "        self.conv_layer = nn.Sequential(nn.Conv2d(1, n_channel, kernel_size),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(n_channel, 2 * n_channel, kernel_size),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(2 * n_channel, 4 * n_channel, kernel_size),\n",
    "                                        nn.BatchNorm2d(4 * n_channel),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(p=0.3),\n",
    "                                        nn.Conv2d(4 * n_channel, 8 * n_channel, kernel_size),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(p=0.4),\n",
    "                                        nn.Conv2d(8 * n_channel, 16 * n_channel, kernel_size),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(p=0.5),\n",
    "                                        nn.Conv2d(16 * n_channel, 32 * n_channel, kernel_size),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(p=0.6)\n",
    "                                        )\n",
    "        def compute_conv2d_size(length):\n",
    "            return  length - (kernel_size - 1) - 1 + 1\n",
    "        \n",
    "        length_out = self.length\n",
    "        depth = 4\n",
    "        \n",
    "        for i in range(depth):\n",
    "            length_out = compute_conv2d_size(length_out)\n",
    "                \n",
    "        # For 10 digits:\n",
    "        concat_size = 640\n",
    "        self.fcout1 = nn.Linear(concat_size, intermediate_output_size)\n",
    "        \n",
    "        # For 0-1 output: \n",
    "        self.fcout2 = nn.Linear(2 * intermediate_output_size,\n",
    "                               final_output_size,\n",
    "                               bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = x[:, 0].view(-1, 1, self.length, self.length)\n",
    "        x2 = x[:, 1].view(-1, 1, self.length, self.length)\n",
    "        # x1.shape = torch.Size([64, 1, 14, 14])\n",
    "        \n",
    "        x1 = self.conv_layer(x1)\n",
    "        # x1.shape = torch.Size([64, 160, 2, 2])\n",
    "        x1 = x1.view(-1, 640)\n",
    "        # x1.shape = torch.Size([64, 640])\n",
    "        \n",
    "        # Size batch x 10 (cipher predictions on image)\n",
    "        out1 = self.fcout1(x1)\n",
    "        # out1.shape = torch.Size([64, 10])\n",
    "        \n",
    "        x2 = self.conv_layer(x2) \n",
    "        x2 = x2.view(-1, 640)\n",
    "        # Size batch x 10 (cipher predictions on image)\n",
    "        out2 = self.fcout1(x2)\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # 0-1 Prediction\n",
    "        # Predict if first image bigger than second\n",
    "        # ------------------------------------------------------------------\n",
    "\n",
    "        # concatenate into size (batch x 20)\n",
    "        #X = self.flatten(X)\n",
    "        output = torch.cat((out1, out2), 1)\n",
    "        # flatten 2D->1D\n",
    "        output_ = self.flatten(output)\n",
    "        \n",
    "        # predict probabilities:\n",
    "        logits = self.fcout2(output)\n",
    "        return out1.view(-1, self.n_outputs), out2.view(-1,\n",
    "                                                        self.n_outputs), logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions:\n",
    "Binary classification with two output units --> so `CrossEntropyLoss()` so need to use `torch.nn.CrossEntropyLoss` instead of `BCELoss` (BCE for 1 digit output). The `Softmax` activation is already included in this loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, w, print_loss=True):\n",
    "    size = len(dataloader.dataset)\n",
    "    train_loss, correct, accuracy_numbers = 0, 0, 0\n",
    "    tp, fp, fn, tn = 0, 0, 0, 0\n",
    "    aucs = []\n",
    "    for batch, (X, y, Y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss:\n",
    "        pred1, pred2, logits = model(X)\n",
    "\n",
    "        # Softmax to get probabilities:\n",
    "        prob = softmax(logits)\n",
    "        \n",
    "        # calculate number of correct predictions:\n",
    "        correct += (prob.argmax(1) == y).type(torch.float).sum().item()\n",
    "        accuracy_numbers += (pred1.argmax(1) == Y[:,0]).type(torch.float).sum().item()\n",
    "        accuracy_numbers += (pred2.argmax(1) == Y[:,1]).type(torch.float).sum().item()\n",
    "        \n",
    "        # roc-auc score: \n",
    "        aucs.append(roc_auc_score(y.detach().numpy(), prob.detach().numpy()[:, 1]))\n",
    "\n",
    "        # [0-1] pred loss:\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        # [0-9] pred loss for each pair:\n",
    "        loss_aux_1 = loss_fn(pred1, Y[:, 0])\n",
    "        loss_aux_2 = loss_fn(pred2, Y[:, 1])\n",
    "        \n",
    "        # true positives and other rates:\n",
    "        tp += (prob.argmax(1) * y).type(torch.float).sum().item()\n",
    "        tn += ((1 - prob.argmax(1)) * (1 - y)).type(\n",
    "                torch.float).sum().item()\n",
    "        fp += ((1 - y) * prob.argmax(1)).sum().type(\n",
    "                torch.float).sum().item()\n",
    "        fn += (y * (1 - prob.argmax(1))).sum().type(\n",
    "                torch.float).sum().item()\n",
    "        \n",
    "        # Backpropagation:\n",
    "        optimizer.zero_grad()\n",
    "        loss = w[0]*loss + w[1] * loss_aux_1 + w[2] * loss_aux_2  # 0.4 is weight for auxillary classifier\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    \n",
    "        loss, current = loss.item(), batch * len(X)\n",
    "        \"\"\"\n",
    "        if print_loss:\n",
    "            if batch % 10 == 0:\n",
    "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\"\"\"\n",
    "\n",
    "    # return average training loss:\n",
    "    train_loss /= size\n",
    "    correct *= 100 / size\n",
    "    accuracy_numbers *= 100 / (2 * size)\n",
    "    auc = sum(aucs)/len(aucs)\n",
    "    \n",
    "    # F1 score:\n",
    "    epsilon = 1e-7\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    f1 = 2 * 100 * (precision * recall) / (precision + recall + epsilon)\n",
    "    \n",
    "    return correct, f1, accuracy_numbers, train_loss, auc\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, e, w, print_loss=True):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    tp, fp, fn, tn, accuracy_numbers = 0, 0, 0, 0, 0\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    aucs = []\n",
    "    with torch.no_grad():\n",
    "        for X, y, Y in dataloader:\n",
    "            pred1, pred2, logits = model(X)\n",
    "            \n",
    "            # [0-1] pred loss:\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            # [0-9] pred loss for each pair:\n",
    "            loss_aux_1 = loss_fn(pred1, Y[:, 0])\n",
    "            loss_aux_2 = loss_fn(pred2, Y[:, 1])\n",
    "            \n",
    "            # sum with weights for total loss: \n",
    "            loss = w[0]*loss + w[1] * loss_aux_1 + w[2] * loss_aux_2 \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Softmax to get probabilities:\n",
    "            prob = softmax(logits)\n",
    "\n",
    "            # calculate number of correct predictions:\n",
    "            correct += (prob.argmax(1) == y).type(torch.float).sum().item()\n",
    "            accuracy_numbers += (pred1.argmax(1) == Y[:,0]).type(torch.float).sum().item()\n",
    "            accuracy_numbers += (pred2.argmax(1) == Y[:,1]).type(torch.float).sum().item()\n",
    "            \n",
    "            # roc-auc score:\n",
    "            aucs.append(roc_auc_score(y.detach().numpy(), prob.detach().numpy()[:, 1]))\n",
    "            \n",
    "            # true positives and other rates:\n",
    "            tp += (prob.argmax(1) * y).type(torch.float).sum().item()\n",
    "            tn += ((1 - prob.argmax(1)) * (1 - y)).type(\n",
    "                torch.float).sum().item()\n",
    "            fp += ((1 - y) * prob.argmax(1)).sum().type(\n",
    "                torch.float).sum().item()\n",
    "            fn += (y * (1 - prob.argmax(1))).sum().type(\n",
    "                torch.float).sum().item()\n",
    "\n",
    "    # return average test loss and accuracy:\n",
    "    test_loss /= size\n",
    "    correct *= 100 / size\n",
    "    accuracy_numbers *= 100 / (2 * size)\n",
    "    auc = sum(aucs)/len(aucs)\n",
    "    \n",
    "    # F1 score:\n",
    "    epsilon = 1e-7\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    f1 = 2 * 100 * (precision * recall) / (precision + recall + epsilon)\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        if print_loss:\n",
    "            print(\n",
    "                f\"Validation Error: \\n Accuracy: {(correct):>0.1f}%, F1: {(f1):>0.1f}%, Accuracy ciphers: {(accuracy_numbers):>0.1f}%, Avg loss: {test_loss:>8f} \\n \"\n",
    "            )\n",
    "    return correct, f1, accuracy_numbers, test_loss, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model,\n",
    "               optimizer,\n",
    "               loss_fn,\n",
    "               w,training_generator, test_generator,\n",
    "               epochs=25,\n",
    "               save=False,\n",
    "               print_loss=False,\n",
    "               print_epoch=False):\n",
    "\n",
    "\n",
    "    train_perf, test_perf = [], []\n",
    "\n",
    "    for t in range(epochs):\n",
    "        if print_epoch:\n",
    "            if t % 10 == 0:\n",
    "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_perf.append(\n",
    "            train_loop(training_generator,\n",
    "                       model,\n",
    "                       loss_fn,\n",
    "                       optimizer,\n",
    "                       w,\n",
    "                       print_loss=print_loss))\n",
    "        test_perf.append(\n",
    "            test_loop(test_generator,\n",
    "                      model,\n",
    "                      loss_fn,\n",
    "                      e=t,\n",
    "                      w=w,\n",
    "                      print_loss=print_loss))\n",
    "    #print(\"Done!\")\n",
    "    if save:\n",
    "        torch.save(\n",
    "            {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_perf': train_perf,\n",
    "                'test_perf': test_perf\n",
    "            }, '../data/{}'.format(type(model).__name__))\n",
    "        print(\"Saved!\")\n",
    "\n",
    "    return train_perf, test_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(train_perf, test_perf):\n",
    "    def sub_plot(axs_id, train_data, test_data, train_label, test_label,\n",
    "                 x_label, title):\n",
    "        axs[axs_id].plot(train_data, label=train_label)\n",
    "        axs[axs_id].plot(test_data, label=test_label)\n",
    "        axs[axs_id].set_xlabel(x_label)\n",
    "        axs[axs_id].set_title(title)\n",
    "        axs[axs_id].legend()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "    train_accs = list(zip(*train_perf))[0]\n",
    "    test_accs = list(zip(*test_perf))[0]\n",
    "    test_f1 = list(zip(*test_perf))[1]\n",
    "    train_f1 = list(zip(*train_perf))[1]\n",
    "    \n",
    "    # Accuracy 0-1 and F1 score:\n",
    "    sub_plot(0, train_accs, test_accs, 'train accuracy', 'test accuracy',\n",
    "             'Num epochs', 'Accuracy')\n",
    "    axs[0].plot(test_f1, label='test_f1')\n",
    "    axs[0].plot(train_f1, label='train_f1')\n",
    "    axs[0].legend()\n",
    "    \n",
    "    # Accuracy on ciphers:\n",
    "    test_accs_ciphers = list(zip(*test_perf))[2]\n",
    "    train_accs_ciphers = list(zip(*train_perf))[2]\n",
    "    sub_plot(1, train_accs_ciphers,  test_accs_ciphers,\n",
    "             'train accuracy','test accuracy', 'Num epochs', 'Accuracy ciphers')\n",
    "    \n",
    "    # Losses:\n",
    "    train_losses = list(zip(*train_perf))[3]\n",
    "    test_losses = list(zip(*test_perf))[3]\n",
    "    sub_plot(2, train_losses, test_losses, 'train loss', 'test loss',\n",
    "             'Num epochs', 'Loss')\n",
    "    \n",
    "    # Roc-auc curve:\n",
    "    train_aucs = list(zip(*train_perf))[4]\n",
    "    test_aucs = list(zip(*test_perf))[4]\n",
    "    sub_plot(3, train_aucs, test_aucs, 'train auc', 'test auc', 'Num epochs', 'ROC AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_runs(performance,\n",
    "                          metrics=['Accuracy', 'F1','Cipher Accuracy','Loss', 'ROC_AUC'],\n",
    "                          style=0):\n",
    "    df = pd.DataFrame(columns=['Run', 'is_Test', 'epoch'] + metrics)\n",
    "    for i in range(len(performance)):\n",
    "        for j in range(2):\n",
    "            df_temp = pd.DataFrame(\n",
    "                performance[i][j],\n",
    "                columns=['Accuracy', 'F1', 'Cipher Accuracy', 'Loss', 'ROC_AUC'\n",
    "                         ]).reset_index().rename(columns={'index': 'epoch'})\n",
    "            df_temp.insert(0, \"is_Test\", j)\n",
    "            df_temp.insert(0, \"Run\", i)\n",
    "            df = df.append(df_temp)\n",
    "            df = df.reset_index().drop(columns=['index'])\n",
    "\n",
    "    sns.set_theme()\n",
    "    for metric in metrics:\n",
    "        if style == 0:\n",
    "            g = sns.lineplot(data=df, x='epoch', y=metric, hue='is_Test')\n",
    "            g.legend(['Train', 'Test'])\n",
    "        if style == 1:\n",
    "            g = sns.lineplot(data=df,\n",
    "                             x='epoch',\n",
    "                             y=metric,\n",
    "                             hue='is_Test',\n",
    "                             style='Run')\n",
    "            g.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.title(\"{} vs {}\".format(metric, \"epoch\"))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Control the randomness\n",
    "# ------------------------------------------------------------------\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Perform n_runs runs\n",
    "# ------------------------------------------------------------------\n",
    "perf = []\n",
    "n_runs = 1\n",
    "\n",
    "params_model = {\n",
    "    'batch_size': 64,\n",
    "    'n_steps': 64,\n",
    "    'n_inputs': 14,\n",
    "    'n_neurons': 50,\n",
    "    'n_outputs': 10\n",
    "}\n",
    "\n",
    "params_t = {\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    # weights given to main and auxiliary losses\n",
    "    'w': [1, 0.8, 0.8]\n",
    "}\n",
    "\n",
    "for i in range(n_runs):\n",
    "    ### ------------------------------------------------------------------\n",
    "    ### Initialize/reset the model and optimizer (i.e. reset the weights)\n",
    "    ### ------------------------------------------------------------------\n",
    "    print(f'Run [{i}/{n_runs}]')\n",
    "    model = ImageRNN(**params_model).to(device)\n",
    "    learning_rate = 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=params_t['learning_rate'])\n",
    "\n",
    "    ### ------------------------------------------------------------------\n",
    "    ### Train and evaluate\n",
    "    ### ------------------------------------------------------------------\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    perf += [\n",
    "        train_eval(model,\n",
    "                   optimizer,\n",
    "                   params_t['loss_fn'],\n",
    "                   params_t['w'],\n",
    "                   params_t['epochs'],\n",
    "                   print_loss=False,\n",
    "                   print_epoch=False)\n",
    "    ]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Plot performance\n",
    "# ------------------------------------------------------------------\n",
    "plot_performance_runs(perf, ['Loss', 'F1','Cipher Accuracy','Accuracy', 'ROC_AUC'])\n",
    "\n",
    "# roc curves\n",
    "\"\"\"\n",
    "y_probas = nn.functional.softmax(model(test_input), dim=1).detach().numpy()\n",
    "y_test = test_target\n",
    "skplt.metrics.plot_roc(y_test, y_probas)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Siamese-RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# control the randomness\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# initialize/reset the model and optimizer (i.e. reset the weights)\n",
    "# ------------------------------------------------------------------\n",
    "params_model = {\n",
    "    'batch_size': 64,\n",
    "    'n_steps': 64,\n",
    "    'n_inputs': 14,\n",
    "    'n_neurons': 50,\n",
    "    'n_outputs': 10\n",
    "}\n",
    "\n",
    "model = ImageRNN(**params_model).to(device)\n",
    "\n",
    "print(\"model: {}\\nParameters:\".format(type(model).__name__))\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "print()\n",
    "\n",
    "params_t = {\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    # weights given to main and auxiliary losses\n",
    "    'w': [1, 0.8, 0.8]\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params_t['learning_rate'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# train and evaluate\n",
    "# ------------------------------------------------------------------\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_perf, test_perf = train_eval(model,\n",
    "                                   optimizer,\n",
    "                                   params_t['loss_fn'], params_t['w'],\n",
    "                                   params_t['epochs'],\n",
    "                                   save=False,\n",
    "                                   print_loss=True,\n",
    "                                   print_epoch=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# plot performance\n",
    "# ------------------------------------------------------------------\n",
    "plot_performance(train_perf, test_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Siamese-RNN 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# control the randomness\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# initialize/reset the model and optimizer (i.e. reset the weights)\n",
    "# ------------------------------------------------------------------\n",
    "params_model = {\n",
    "    'batch_size': 64,\n",
    "    'n_steps': 64,\n",
    "    'n_inputs': 14,\n",
    "    'n_neurons': 50,\n",
    "    'n_outputs': 10\n",
    "}\n",
    "\n",
    "model = ImageRNN_2(**params_model).to(device)\n",
    "\n",
    "print(\"model: {}\\nParameters:\".format(type(model).__name__))\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "print()\n",
    "\n",
    "params_t = {\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    # weights given to main and auxiliary losses\n",
    "    'w': [1, 0.8, 0.8]\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params_t['learning_rate'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# train and evaluate\n",
    "# ------------------------------------------------------------------\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_perf, test_perf = train_eval(model,\n",
    "                                   optimizer,\n",
    "                                   params_t['loss_fn'], params_t['w'],\n",
    "                                   params_t['epochs'],\n",
    "                                   save=False,\n",
    "                                   print_loss=True,\n",
    "                                   print_epoch=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# plot performance\n",
    "# ------------------------------------------------------------------\n",
    "plot_performance(train_perf, test_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ImageRNN_2\n",
      "Parameters:\n",
      "torch.Size([50, 14])\n",
      "torch.Size([50, 50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([150, 20])\n",
      "torch.Size([150])\n",
      "torch.Size([150, 150])\n",
      "torch.Size([150])\n",
      "torch.Size([2, 150])\n",
      "torch.Size([2])\n",
      "\n",
      "Run: 1/10\n",
      "(68.9, 72.45349365903061, 53.85, 0.04982289886474609, 0.7727789072925929)\n",
      "Run: 2/10\n",
      "(69.9, 72.10379480251976, 52.7, 0.0527953028678894, 0.7852484855917605)\n",
      "Run: 3/10\n",
      "(69.10000000000001, 71.72918071426872, 53.35, 0.05151599407196045, 0.7695533773450342)\n",
      "Run: 4/10\n",
      "(72.2, 74.86437111667775, 59.35, 0.051769250392913815, 0.7742951849298675)\n",
      "Run: 5/10\n",
      "(69.10000000000001, 70.37391636717999, 59.550000000000004, 0.051922221899032596, 0.7602308530135335)\n",
      "Run: 6/10\n",
      "(73.10000000000001, 76.46543680918307, 59.900000000000006, 0.05153920006752014, 0.7943658762411963)\n",
      "Run: 7/10\n",
      "(74.0, 77.03179710916949, 59.85, 0.046590493202209475, 0.8062588537844837)\n",
      "Run: 8/10\n",
      "(73.60000000000001, 77.20206753091092, 60.75, 0.048461812734603885, 0.7972592769271908)\n",
      "Run: 9/10\n",
      "(70.9, 74.49605109145955, 62.1, 0.049384771585464476, 0.7926210907244131)\n",
      "Run: 10/10\n",
      "(73.4, 75.59632526420368, 61.150000000000006, 0.04818854379653931, 0.8236600282833757)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Runs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy_cipher</th>\n",
       "      <th>Loss</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68.9</td>\n",
       "      <td>72.4535</td>\n",
       "      <td>53.85</td>\n",
       "      <td>0.0498229</td>\n",
       "      <td>0.772779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>69.9</td>\n",
       "      <td>72.1038</td>\n",
       "      <td>52.7</td>\n",
       "      <td>0.0527953</td>\n",
       "      <td>0.785248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69.1</td>\n",
       "      <td>71.7292</td>\n",
       "      <td>53.35</td>\n",
       "      <td>0.051516</td>\n",
       "      <td>0.769553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72.2</td>\n",
       "      <td>74.8644</td>\n",
       "      <td>59.35</td>\n",
       "      <td>0.0517693</td>\n",
       "      <td>0.774295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>69.1</td>\n",
       "      <td>70.3739</td>\n",
       "      <td>59.55</td>\n",
       "      <td>0.0519222</td>\n",
       "      <td>0.760231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>73.1</td>\n",
       "      <td>76.4654</td>\n",
       "      <td>59.9</td>\n",
       "      <td>0.0515392</td>\n",
       "      <td>0.794366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>77.0318</td>\n",
       "      <td>59.85</td>\n",
       "      <td>0.0465905</td>\n",
       "      <td>0.806259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>73.6</td>\n",
       "      <td>77.2021</td>\n",
       "      <td>60.75</td>\n",
       "      <td>0.0484618</td>\n",
       "      <td>0.797259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>70.9</td>\n",
       "      <td>74.4961</td>\n",
       "      <td>62.1</td>\n",
       "      <td>0.0493848</td>\n",
       "      <td>0.792621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>73.4</td>\n",
       "      <td>75.5963</td>\n",
       "      <td>61.15</td>\n",
       "      <td>0.0481885</td>\n",
       "      <td>0.82366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Runs Accuracy       F1 Accuracy_cipher       Loss       AUC\n",
       "0     0     68.9  72.4535           53.85  0.0498229  0.772779\n",
       "1     1     69.9  72.1038            52.7  0.0527953  0.785248\n",
       "2     2     69.1  71.7292           53.35   0.051516  0.769553\n",
       "3     3     72.2  74.8644           59.35  0.0517693  0.774295\n",
       "4     4     69.1  70.3739           59.55  0.0519222  0.760231\n",
       "5     5     73.1  76.4654            59.9  0.0515392  0.794366\n",
       "6     6       74  77.0318           59.85  0.0465905  0.806259\n",
       "7     7     73.6  77.2021           60.75  0.0484618  0.797259\n",
       "8     8     70.9  74.4961            62.1  0.0493848  0.792621\n",
       "9     9     73.4  75.5963           61.15  0.0481885   0.82366"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# randomize runs:\n",
    "# ------------------------------------------------------------------\n",
    "# initialize/reset the model and optimizer (i.e. reset the weights)\n",
    "# ------------------------------------------------------------------\n",
    "params_model = {\n",
    "    'batch_size': 64,\n",
    "    'n_steps': 64,\n",
    "    'n_inputs': 14,\n",
    "    'n_neurons': 50,\n",
    "    'n_outputs': 10\n",
    "}\n",
    "\n",
    "model = ImageRNN_2(**params_model).to(device)\n",
    "\n",
    "print(\"model: {}\\nParameters:\".format(type(model).__name__))\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "print()\n",
    "\n",
    "params_t = {\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 1e-3,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    # weights given to main and auxiliary losses\n",
    "    'w': [1, 0.8, 0.8]\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params_t['learning_rate'])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "N = 10\n",
    "random_seeds = random.sample(range(1, 30), 10)\n",
    "metrics = pd.DataFrame(\n",
    "    columns=['Runs','Accuracy', 'F1', 'Accuracy_cipher', 'Loss', 'AUC'])\n",
    "metrics['Runs'] = range(N)\n",
    "\n",
    "for i in range(N):\n",
    "    print('Run: {}/{}'.format(i + 1, N))\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(\n",
    "        1000)\n",
    "    training_set = Dataset(train_input, train_target, train_classes)\n",
    "    test_set = Dataset(test_input, test_target, test_classes)\n",
    "    \n",
    "    # Data loader for model, change num_workers when on GPU:\n",
    "    params_ = {'batch_size': 64, 'shuffle': True, 'num_workers': 0}\n",
    "    training_generator = torch.utils.data.DataLoader(training_set, **params_)\n",
    "    test_generator = torch.utils.data.DataLoader(test_set, **params_)\n",
    "    \n",
    "    train_perf, test_perf = train_eval(model,\n",
    "                                       optimizer,\n",
    "                                       params_t['loss_fn'],\n",
    "                                       params_t['w'],\n",
    "                                       training_generator,\n",
    "                                       test_generator,\n",
    "                                       params_t['epochs'],\n",
    "                                       save=False,\n",
    "                                       print_loss=False,\n",
    "                                       print_epoch=False)\n",
    "    print(test_perf[-1])\n",
    "    correct, f1, accuracy_numbers, train_loss, auc = test_perf[-1]\n",
    "    metrics.iloc[i,1]= correct\n",
    "    metrics.iloc[i,2] = f1\n",
    "    metrics.iloc[i,3] = accuracy_numbers\n",
    "    metrics.iloc[i,4]= train_loss\n",
    "    metrics.iloc[i,5] = auc\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Runs                4.500000\n",
       " Accuracy           71.420000\n",
       " F1                 74.231643\n",
       " Accuracy_cipher    58.255000\n",
       " Loss                0.050199\n",
       " AUC                 0.787627\n",
       " dtype: float64,\n",
       " Runs               3.027650\n",
       " Accuracy           2.067097\n",
       " F1                 2.422594\n",
       " Accuracy_cipher    3.525104\n",
       " Loss               0.002016\n",
       " AUC                0.019119\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean(), metrics.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic convnet: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# control the randomness\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# initialize/reset the model and optimizer (i.e. reset the weights)\n",
    "# ------------------------------------------------------------------\n",
    "params_model = {\n",
    "    'batch_size': 64,\n",
    "    'n_steps': 64,\n",
    "    'n_inputs': 14,\n",
    "    'n_neurons': 50,\n",
    "    'n_outputs': 10\n",
    "}\n",
    "\n",
    "model = Conv_basic().to(device)\n",
    "\n",
    "print(\"model: {}\\nParameters:\".format(type(model).__name__))\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "print()\n",
    "\n",
    "params_t = {\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    # weights given to main and auxiliary losses\n",
    "    'w': [1, 0.8, 0.8]\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params_t['learning_rate'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# train and evaluate\n",
    "# ------------------------------------------------------------------\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_perf, test_perf = train_eval(model,\n",
    "                                   optimizer,\n",
    "                                   params_t['loss_fn'],\n",
    "                                   params_t['w'],\n",
    "                                   params_t['epochs'],\n",
    "                                   save=False,\n",
    "                                   print_loss=True,\n",
    "                                   print_epoch=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# plot performance\n",
    "# ------------------------------------------------------------------\n",
    "plot_performance(train_perf, test_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Conv_basic\n",
      "Parameters:\n",
      "torch.Size([10, 1, 5, 5])\n",
      "torch.Size([10])\n",
      "torch.Size([20, 10, 5, 5])\n",
      "torch.Size([20])\n",
      "torch.Size([30, 40])\n",
      "torch.Size([30])\n",
      "torch.Size([10, 30])\n",
      "torch.Size([10])\n",
      "torch.Size([2, 20])\n",
      "\n",
      "Run: 1/10\n",
      "(73.9, 75.07162822403426, 68.2, 0.03203369951248169, 0.8339582987254909)\n",
      "Run: 2/10\n",
      "(78.60000000000001, 79.84933585169613, 72.60000000000001, 0.027249876260757446, 0.8759174062024448)\n",
      "Run: 3/10\n",
      "(80.10000000000001, 81.99094521288292, 78.65, 0.02354672122001648, 0.8949376791273713)\n",
      "Run: 4/10\n",
      "(80.9, 82.6835851940273, 78.95, 0.022619142532348632, 0.8967654293156648)\n",
      "Run: 5/10\n",
      "(82.60000000000001, 84.38060540190328, 82.2, 0.021699075341224672, 0.8997894884161121)\n",
      "Run: 6/10\n",
      "(82.4, 84.17265685551051, 82.2, 0.024346720218658448, 0.8953469068996494)\n",
      "Run: 7/10\n",
      "(82.7, 84.53976263946917, 81.0, 0.02281933259963989, 0.9087170995886285)\n",
      "Run: 8/10\n",
      "(84.30000000000001, 85.76608746044158, 81.9, 0.022233237862586974, 0.9165412220480633)\n",
      "Run: 9/10\n",
      "(81.80000000000001, 82.69961475729765, 81.85000000000001, 0.02329978632926941, 0.8928135592288562)\n",
      "Run: 10/10\n",
      "(83.0, 84.4890460800725, 82.55000000000001, 0.02348032355308533, 0.9083903029073883)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Runs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy_cipher</th>\n",
       "      <th>Loss</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>75.0716</td>\n",
       "      <td>68.2</td>\n",
       "      <td>0.0320337</td>\n",
       "      <td>0.833958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78.6</td>\n",
       "      <td>79.8493</td>\n",
       "      <td>72.6</td>\n",
       "      <td>0.0272499</td>\n",
       "      <td>0.875917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>80.1</td>\n",
       "      <td>81.9909</td>\n",
       "      <td>78.65</td>\n",
       "      <td>0.0235467</td>\n",
       "      <td>0.894938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>80.9</td>\n",
       "      <td>82.6836</td>\n",
       "      <td>78.95</td>\n",
       "      <td>0.0226191</td>\n",
       "      <td>0.896765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>82.6</td>\n",
       "      <td>84.3806</td>\n",
       "      <td>82.2</td>\n",
       "      <td>0.0216991</td>\n",
       "      <td>0.899789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>82.4</td>\n",
       "      <td>84.1727</td>\n",
       "      <td>82.2</td>\n",
       "      <td>0.0243467</td>\n",
       "      <td>0.895347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>82.7</td>\n",
       "      <td>84.5398</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0228193</td>\n",
       "      <td>0.908717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>84.3</td>\n",
       "      <td>85.7661</td>\n",
       "      <td>81.9</td>\n",
       "      <td>0.0222332</td>\n",
       "      <td>0.916541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>81.8</td>\n",
       "      <td>82.6996</td>\n",
       "      <td>81.85</td>\n",
       "      <td>0.0232998</td>\n",
       "      <td>0.892814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "      <td>84.489</td>\n",
       "      <td>82.55</td>\n",
       "      <td>0.0234803</td>\n",
       "      <td>0.90839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Runs Accuracy       F1 Accuracy_cipher       Loss       AUC\n",
       "0     0     73.9  75.0716            68.2  0.0320337  0.833958\n",
       "1     1     78.6  79.8493            72.6  0.0272499  0.875917\n",
       "2     2     80.1  81.9909           78.65  0.0235467  0.894938\n",
       "3     3     80.9  82.6836           78.95  0.0226191  0.896765\n",
       "4     4     82.6  84.3806            82.2  0.0216991  0.899789\n",
       "5     5     82.4  84.1727            82.2  0.0243467  0.895347\n",
       "6     6     82.7  84.5398              81  0.0228193  0.908717\n",
       "7     7     84.3  85.7661            81.9  0.0222332  0.916541\n",
       "8     8     81.8  82.6996           81.85  0.0232998  0.892814\n",
       "9     9       83   84.489           82.55  0.0234803   0.90839"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# randomize runs:\n",
    "# ------------------------------------------------------------------\n",
    "# initialize/reset the model and optimizer (i.e. reset the weights)\n",
    "# ------------------------------------------------------------------\n",
    "params_model = {\n",
    "    'batch_size': 64,\n",
    "    'n_steps': 64,\n",
    "    'n_inputs': 14,\n",
    "    'n_neurons': 50,\n",
    "    'n_outputs': 10\n",
    "}\n",
    "\n",
    "model = Conv_basic().to(device)\n",
    "\n",
    "print(\"model: {}\\nParameters:\".format(type(model).__name__))\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "print()\n",
    "\n",
    "params_t = {\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    # weights given to main and auxiliary losses\n",
    "    'w': [1, 0.8, 0.8]\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params_t['learning_rate'])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "N = 10\n",
    "random_seeds = random.sample(range(1, 30), 10)\n",
    "metrics = pd.DataFrame(\n",
    "    columns=['Runs','Accuracy', 'F1', 'Accuracy_cipher', 'Loss', 'AUC'])\n",
    "metrics['Runs'] = range(N)\n",
    "\n",
    "for i in range(N):\n",
    "    print('Run: {}/{}'.format(i + 1, N))\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(\n",
    "        1000)\n",
    "    training_set = Dataset(train_input, train_target, train_classes)\n",
    "    test_set = Dataset(test_input, test_target, test_classes)\n",
    "    \n",
    "    # Data loader for model, change num_workers when on GPU:\n",
    "    params_ = {'batch_size': 64, 'shuffle': True, 'num_workers': 0}\n",
    "    training_generator = torch.utils.data.DataLoader(training_set, **params_)\n",
    "    test_generator = torch.utils.data.DataLoader(test_set, **params_)\n",
    "    \n",
    "    train_perf, test_perf = train_eval(model,\n",
    "                                       optimizer,\n",
    "                                       params_t['loss_fn'],\n",
    "                                       params_t['w'],\n",
    "                                       training_generator,\n",
    "                                       test_generator,\n",
    "                                       params_t['epochs'],\n",
    "                                       save=False,\n",
    "                                       print_loss=False,\n",
    "                                       print_epoch=False)\n",
    "    print(test_perf[-1])\n",
    "    correct, f1, accuracy_numbers, train_loss, auc = test_perf[-1]\n",
    "    metrics.iloc[i,1]= correct\n",
    "    metrics.iloc[i,2] = f1\n",
    "    metrics.iloc[i,3] = accuracy_numbers\n",
    "    metrics.iloc[i,4]= train_loss\n",
    "    metrics.iloc[i,5] = auc\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Runs                4.500000\n",
       " Accuracy           81.030000\n",
       " F1                 82.564327\n",
       " Accuracy_cipher    79.010000\n",
       " Loss                0.024333\n",
       " AUC                 0.892318\n",
       " dtype: float64,\n",
       " Runs               3.027650\n",
       " Accuracy           2.979952\n",
       " F1                 3.120127\n",
       " Accuracy_cipher    4.845834\n",
       " Loss               0.003105\n",
       " AUC                0.023287\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean(), metrics.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper Convnet: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# control the randomness\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# initialize/reset the model and optimizer (i.e. reset the weights)\n",
    "# ------------------------------------------------------------------\n",
    "params_model = {\n",
    "    'batch_size': 64,\n",
    "    'n_steps': 64,\n",
    "    'n_inputs': 14,\n",
    "    'n_neurons': 50,\n",
    "    'n_outputs': 10\n",
    "}\n",
    "\n",
    "model = SiameseConvNet2().to(device)\n",
    "\n",
    "print(\"model: {}\\nParameters:\".format(type(model).__name__))\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "print()\n",
    "\n",
    "params_t = {\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    # weights given to main and auxiliary losses\n",
    "    'w': [1, 0.8, 0.8]\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params_t['learning_rate'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# train and evaluate\n",
    "# ------------------------------------------------------------------\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_perf, test_perf = train_eval(model,\n",
    "                                   optimizer,\n",
    "                                   params_t['loss_fn'],\n",
    "                                   params_t['w'],\n",
    "                                   params_t['epochs'],\n",
    "                                   save=False,\n",
    "                                   print_loss=True,\n",
    "                                   print_epoch=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# plot performance\n",
    "# ------------------------------------------------------------------\n",
    "plot_performance(train_perf, test_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a few predictions:\n",
    "params_ = {'batch_size': 64, 'shuffle': True, 'num_workers': 0}\n",
    "test_generator = torch.utils.data.DataLoader(test_set, **params_)\n",
    "size = len(test_generator.dataset)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "fig, ax = plt.subplots(6, 2, figsize=(10, 18))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, (X, y, Y) in enumerate(test_generator):\n",
    "        if batch == 0:\n",
    "            pred1, pred2, pred = model(X)\n",
    "            prob = softmax(pred)\n",
    "            prediction = prob.argmax(1).type(torch.float)\n",
    "            pred_cipher_1 = pred1.argmax(1).type(torch.float)\n",
    "            pred_cipher_2 = pred2.argmax(1).type(torch.float)\n",
    "            for j in range(6):\n",
    "                im1 = X[j][0, :, :]\n",
    "                im2 = X[j][1, :, :]\n",
    "                target = y[j]\n",
    "                classes = Y[j]\n",
    "                pred = prediction[j]\n",
    "                pred1 = int(pred_cipher_1[j])\n",
    "                pred2 = int(pred_cipher_2[j])\n",
    "                ax[j, 0].imshow(im1, cmap='gray')\n",
    "                ax[j, 1].imshow(im2, cmap='gray')\n",
    "                ax[j, 0].set_title(\n",
    "                    f'Cipher (true/pred): {classes[0]}/{pred1}, target: {target}, pred: {pred}')\n",
    "                ax[j, 1].set_title(f'Cipher (true/pred): {classes[1]}/{pred2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
